{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker\n",
    "==\n",
    "\n",
    "Docker es una herramienta que ya lleva varios años tomando popularidad en los ambientes de desarrollo de software. Este popularidad se va extendiendo a otras areas más allá del desarrollo de software. ¿Por qué?\n",
    "\n",
    "1. Motivación al uso de docker\n",
    "2. Dockerfile\n",
    "3. Dockerfile en la ciencia de datos\n",
    "\n",
    "\n",
    "### Bibliografía\n",
    "\n",
    "1. [Docker for Data Science: Building Scalable and Extensible Data Infrastructure Around the Jupyter Notebook Server](https://libgen.is/book/index.php?md5=7521B3D87DF447AB03F259271A5C2149)\n",
    "2. [Learning PySpark](https://libgen.is/book/index.php?md5=8A78A93D5EB86F511A74910DC09E3DD6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker + Pyspark\n",
    "==\n",
    "\n",
    "Si usted no sabe pyspark no sabe big data, o por lo menos, big data actual.\n",
    "\n",
    "![](https://echanclarityinsights.github.io/images/2018-12-23/spark-meme.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tareas guiadas:\n",
    "0. Construir unas credenciales para el cliente en Amazon Web Services\n",
    "1. Leer Iris con pyspark\n",
    "2. Leer Iris con pyspark y guardarlo como parquet\n",
    "3. Guardarlo en un bucket s3 particionado por tipo de flor\n",
    "4. Encontrar mediante sql las dos flores del mismo tipo más \"diferentes\" mediante distancia Euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ronald Fisher** tiene como idea determinar cuales pares de flores del tipo iris son los más distintos posibles pero que son del mismo tipo, diseñe un programa en pyspark que de respuesta ¿cuáles son los pares más distintos posibles siendo que son del mismo tipo de flor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sepal.length: string, sepal.width: string, petal.length: string, petal.width: string, variety: string]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.options(header=True).csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = spark.read.options(header=True, inferSchema=True).csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+---+\n",
      "|sepal.length|sepal.width|petal.length|petal.width|variety| id|\n",
      "+------------+-----------+------------+-----------+-------+---+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|  0|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|  1|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|  2|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|  3|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|  4|\n",
      "|         5.4|        3.9|         1.7|        0.4| Setosa|  5|\n",
      "|         4.6|        3.4|         1.4|        0.3| Setosa|  6|\n",
      "|         5.0|        3.4|         1.5|        0.2| Setosa|  7|\n",
      "|         4.4|        2.9|         1.4|        0.2| Setosa|  8|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|  9|\n",
      "|         5.4|        3.7|         1.5|        0.2| Setosa| 10|\n",
      "|         4.8|        3.4|         1.6|        0.2| Setosa| 11|\n",
      "|         4.8|        3.0|         1.4|        0.1| Setosa| 12|\n",
      "|         4.3|        3.0|         1.1|        0.1| Setosa| 13|\n",
      "|         5.8|        4.0|         1.2|        0.2| Setosa| 14|\n",
      "|         5.7|        4.4|         1.5|        0.4| Setosa| 15|\n",
      "|         5.4|        3.9|         1.3|        0.4| Setosa| 16|\n",
      "|         5.1|        3.5|         1.4|        0.3| Setosa| 17|\n",
      "|         5.7|        3.8|         1.7|        0.3| Setosa| 18|\n",
      "|         5.1|        3.8|         1.5|        0.3| Setosa| 19|\n",
      "+------------+-----------+------------+-----------+-------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.write.mode(\"overwrite\").parquet(\"./iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 = iris\n",
    "\n",
    "iris_join = iris.join(iris2, iris.variety == iris2.variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal.length',\n",
       " 'sepal.width',\n",
       " 'petal.length',\n",
       " 'petal.width',\n",
       " 'variety',\n",
       " 'id',\n",
       " 'sepal.length',\n",
       " 'sepal.width',\n",
       " 'petal.length',\n",
       " 'petal.width',\n",
       " 'variety',\n",
       " 'id']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_join.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_join = iris_join.toDF(*[\"sepal_length\", \n",
    "                     \"sepal_width\", \n",
    "                     \"petal_length\", \n",
    "                     \"petal_width\", \n",
    "                     \"variety\", \n",
    "                     \"id\",\n",
    "                     \"sepal_length2\", \n",
    "                     \"sepal_width2\", \n",
    "                     \"petal_length2\", \n",
    "                     \"petal_width2\", \n",
    "                     \"variety2\",\n",
    "                     \"id2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_join = iris_join.withColumn(\"distancia\", (iris_join.sepal_length - iris_join.sepal_length2)**2  + (iris_join.sepal_width - iris_join.sepal_width2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "resume = iris_join.groupBy(\"variety\").agg(max(\"distancia\").alias(\"distancia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+-----------------+\n",
      "|  variety2| id|id2|        distancia|\n",
      "+----------+---+---+-----------------+\n",
      "|    Setosa| 15| 41|5.850000000000002|\n",
      "|    Setosa| 41| 15|5.850000000000002|\n",
      "|Versicolor| 50| 60|             5.44|\n",
      "|Versicolor| 60| 50|             5.44|\n",
      "| Virginica|106|131|            10.69|\n",
      "| Virginica|131|106|            10.69|\n",
      "+----------+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(iris_join\n",
    "     .join(resume,iris_join.distancia ==  resume.distancia, \"inner\")\n",
    "     .select(iris_join.variety2, iris_join.id,iris_join.id2,iris_join.distancia)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nspark.conf.set(\"fs.s3n.awsAccessKeyId\", aws_access_key_id)\\nspark.conf.set(\"fs.s3n.awsSecretAccessKey\", aws_secret_access_key)\\nspark.conf.set(\"fs.s3.awsAccessKeyId\", aws_access_key_id)\\nspark.conf.set(\"fs.s3.awsSecretAccessKey\", aws_secret_access_key)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "spark.conf.set(\"fs.s3n.awsAccessKeyId\", aws_access_key_id)\n",
    "spark.conf.set(\"fs.s3n.awsSecretAccessKey\", aws_secret_access_key)\n",
    "spark.conf.set(\"fs.s3.awsAccessKeyId\", aws_access_key_id)\n",
    "spark.conf.set(\"fs.s3.awsSecretAccessKey\", aws_secret_access_key)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
